{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a4dd06",
   "metadata": {},
   "source": [
    "# [Spatial Trasformer Networks](https://docs.pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ac69e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7962fba4a530>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# License: BSD\n",
    "# Author: Ghassen Hamrouni\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "351e0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='.', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])), batch_size=64, shuffle=True, num_workers=4)\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='.', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "869ef0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c20a3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "#\n",
    "# A simple test procedure to measure the STN performances on MNIST.\n",
    "#\n",
    "\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fc81e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.062130\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.052178\n",
      "\n",
      "Test set: Average loss: 0.4794, Accuracy: 8643/10000 (86%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.876828\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.026174\n",
      "\n",
      "Test set: Average loss: 0.0344, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.055344\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.036486\n",
      "\n",
      "Test set: Average loss: 0.0379, Accuracy: 9889/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.008139\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.061157\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.063104\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.229795\n",
      "\n",
      "Test set: Average loss: 0.0326, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.118483\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.072764\n",
      "\n",
      "Test set: Average loss: 0.0367, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.025812\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.045788\n",
      "\n",
      "Test set: Average loss: 0.0819, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.114341\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.039428\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.076353\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.107352\n",
      "\n",
      "Test set: Average loss: 0.0324, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.188820\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.026425\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.032888\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.021345\n",
      "\n",
      "Test set: Average loss: 0.0307, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.094504\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.029799\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.024950\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.073233\n",
      "\n",
      "Test set: Average loss: 0.0371, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.026506\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.017385\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.095136\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.032762\n",
      "\n",
      "Test set: Average loss: 0.0480, Accuracy: 9865/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.204846\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.048529\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.070102\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.017720\n",
      "\n",
      "Test set: Average loss: 0.0355, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.052097\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.053226\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.067714\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.008945\n",
      "\n",
      "Test set: Average loss: 0.0324, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.024742\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.073024\n",
      "\n",
      "Test set: Average loss: 0.0336, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.058089\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.080359\n",
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.071470\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.083408\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.047998\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.025280\n",
      "\n",
      "Test set: Average loss: 0.0322, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.032284\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.033974\n",
      "\n",
      "Test set: Average loss: 0.0345, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.041990\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.034130\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.065556\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.079986\n",
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.005733\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 0.072282\n",
      "\n",
      "Test set: Average loss: 0.0339, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.030110\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.037848\n",
      "\n",
      "Test set: Average loss: 0.0483, Accuracy: 9860/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.033302\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.065715\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.006003\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.014873\n",
      "\n",
      "Test set: Average loss: 0.0299, Accuracy: 9914/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "# We want to visualize the output of the spatial transformers layer\n",
    "# after the training, we visualize a batch of input images and\n",
    "# the corresponding transformed batch using STN.\n",
    "\n",
    "\n",
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "\n",
    "for epoch in range(1, 30 + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# Visualize the STN transformation on some input batch\n",
    "visualize_stn()\n",
    "\n",
    "# plt.ioff()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da1263db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def visualize_stn(save_path=\"stn_output.png\"):\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of training data\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "\n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "\n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "\n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "\n",
    "        # Plot\n",
    "        f, axarr = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "        axarr[0].axis(\"off\")\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "        axarr[1].axis(\"off\")\n",
    "\n",
    "        # ðŸ”¥ SAVE AS PNG\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"[+] Saved STN visualization â†’ {save_path}\")\n",
    "\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2e675d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Saved STN visualization â†’ outputs/stn_output.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'outputs/stn_output.png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "visualize_stn(\"outputs/stn_output.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a9e56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f519d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26334998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8ac73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b312d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921276c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
